# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import shap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


df = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn 2.csv')


df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df.dropna(subset=['TotalCharges'], inplace=True)
df.drop('customerID', axis=1, inplace=True)

df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})

X = df.drop('Churn', axis=1)
y = df['Churn']


numerical_features = X.select_dtypes(include=np.number).columns.tolist()
categorical_features = X.select_dtypes(include='object').columns.tolist()

binary_cols = [col for col in categorical_features if df[col].nunique() == 2]

multi_cols = [col for col in categorical_features if df[col].nunique() > 2]


preprocessor = ColumnTransformer(
    transformers=[

        ('num', StandardScaler(), numerical_features),

        ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'), multi_cols),

        ('label', OneHotEncoder(handle_unknown='ignore', drop='if_binary'), binary_cols)
    ],
    remainder='passthrough'
)

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', xgb.XGBClassifier(
        objective='binary:logistic',
        use_label_encoder=False,
        eval_metric='logloss',

        n_estimators=500,
        learning_rate=0.05,
        max_depth=5,
        subsample=0.7,
        colsample_bytree=0.7,
        random_state=42
    ))
])


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


pipeline.fit(X_train, y_train)


y_pred_proba = pipeline.predict_proba(X_test)[:, 1]
y_pred = pipeline.predict(X_test)
auc_score = roc_auc_score(y_test, y_pred_proba)

print(f"--- Model Evaluation ---")
print(f"ROC-AUC Score: {auc_score:.4f} (Goal: > 0.85 for high score)")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))


feature_names = list(pipeline['preprocessor'].get_feature_names_out())

model = pipeline['classifier']

X_test_processed = pipeline['preprocessor'].transform(X_test)


explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test_processed)

print("\n--- SHAP Global Interpretation (Beeswarm Plot) ---")

print("Run the shap.summary_plot() function in a notebook environment to visualize the global feature importance.")


churn_customer_index = np.where(y_pred_proba > 0.8)[0][0]
X_churn_example = X_test_processed[churn_customer_index, :]


print("\n--- SHAP Local Interpretation (Force Plot for a high-risk Churn Customer) ---")

print("\n--- Generating SHAP Global Beeswarm Plot ---")

shap.summary_plot(
    shap_values,
    X_test_processed,
    feature_names=feature_names,
    plot_type="dot",
    show=True
)


print("\n--- Generating SHAP Local Force Plot ---")
#
churn_customer_index = np.where(y_pred_proba > 0.8)[0][0]
X_churn_original = X_test.iloc[churn_customer_index, :]
X_churn_processed = X_test_processed[churn_customer_index, :]

shap.force_plot(
    explainer.expected_value,
    shap_values[churn_customer_index, :],
    feature_names=feature_names,
    matplotlib=True,
    show=True
)

print(f"\nExample Customer Features (Original Data):\n{X_churn_original}")